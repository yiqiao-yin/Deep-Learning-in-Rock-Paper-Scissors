# Deep Learning in Rock, Paper, and Scissors

This is a mini project (I did it for fun!) on multi-label classification using deep learning.

# Acknowledgement

This mini project is sourced from Convolutional Neural Network in TensorFlow taught by Professor Andrew Ng and Google veteran Laurence Moroney on Coursera. It is also a part of the TensorFlow Concentration Certificate.

# Data

Rock Paper Scissors is a dataset containing 2,892 images of diverse hands in Rock/Paper/Scissors poses. It is licensed [CC By 2.0](https://creativecommons.org/licenses/by/2.0/) and available for all purposes, but it’s intent is primarily for learning and research.

Rock Paper Scissors contains images from a variety of different hands,  from different races, ages and genders, posed into Rock / Paper or Scissors and labelled as such. You can download the [training set here](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip), and the [test set here](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip). These images have all been generated using CGI techniques as an experiment in determining if a CGI-based dataset can be used for classification against real images. I also generated a few images that you can use for predictions. You can find them [here](https://github.com/yiqiao-yin/Deep-Learning-in-Rock-Paper-Scissors/tree/master/figs).

Note that all of this data is posed against a white background.

Each image is 300×300 pixels in 24-bit color

